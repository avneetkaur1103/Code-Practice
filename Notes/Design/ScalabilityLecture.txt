* Web(Shared) Hosting vs VPSes: Sharing host means sharing server(s) and its resources with other websites - storage, bandwidth, etc. Virtual Private Server creates a virtual environment that imitates a dedicated server (where you get a chunk of server(or VM), and all its resources, to yourself), but within a shared hosting environment. VPS are more secure and outperforms shared hosting. Though owner of VPS server might have access to VM, depending on hypervisor used.
Example - Amazon's EC2 (Elastic Compute Cloud), lets you self service - spawn and create multiple VMs (web or database - on demand) as long one is willing to pay some amount per minute; can power off VMs when popularity subsides.
SFTP more secure as comp to FTP - provides data encryption (usename/pwds).

* Vertical Scaling vs Horizontal Scaling: In vertical scaling we can increase - CPU (Cores,Cache), Disk, RAM, etc. But we are gonna hit threshold  at somepoint, run out of either financial resources to upgrade or state of art in technology.

- How to do Vertical Scaling:
Older CPU handled multiple processes with single processor(by giving each process a split second of their time), but dual/quad cores truely work in parallel.quad core can handle 4 processes at once , but with multihreading it gives an impression of many more.
Types of Disk/harddrives - PATA(old), SATA(7200 rpm), SAS - serial attached SCSI (10k-15k rpm), SSD - Solid state drives(electrically faster as comp to mechanical drives)

- How to do Horizontal Scaling:
Architecting system so that we use cheaper hardware and acheive parallelism in our topology.

Limitations-
a. Round-robin &  DNS- store multiple IPs for a URL & return a next ip in the circle each time queried. This can overload some of the server, sending all heavy queries to them.
b. OS & Browser IP Caching avoids querying DNS server again n again and forwards request to same web server.(till TTL)

Instead we can choose LB level rounds robin - Single IP for load balancer, no DNS caching issue, Web servers can have private IP addresses(secure).
LB communicates with Web Servers using TCP/IP - sending packets (same btw client & LB).

Although with above round robin we end up skipping session & cookie handling problems which is valid only in that server machine. we now have to keep separate line of storage server(or at LB itself in case of single LB which would be consistent) to keep these session info - maybe a Network file system or DB like MySql(Replication).

* Sticky Sessions - Session is preserved even if we visit a website multiple times, end up on same web server.
- Cookies: Few Kbs, LB can put a large number in cookie which is mapped to web server in LB, which end user sends back in subsequent requests.
(LB here has the ability to work @HTTP level) => The system breaks down if cookies are disabled.

- Shared session
* RAID: Redundant Array of Independent Disks - used to store shared sessions in LB. but still has h/w limitations like Power supply, limited storage, etc.
  - RAID 0 - 2HD, stripe data across disks, good performance
  - RAID 1 - 2 HD, Mirror data in both, Fault Tolerance
  - RAID10 - 4 HD, RAID0+RAID1
  - RAID5/6 - 1/2 out of 3/4 HD used for redundancy(better than RAID1)
  
* php accelerators - generates "compiled version" of php files, so code is not parsed , if visited again.

* Caching:
- .html- CraingsList caches dynamically generated .html pages as caches => gives a good performance benefit as spitting out static content is pretty fast, but also compromises on the fact if there are any changes is html template all those files needs to be regenerated & uses a lot more storage as it doesn't take advantage of having a common template for all .html files. 
- mysql query cache - add query_cache_type = 1 in conf file.Cache identically executed query
- memcached 

* Data querying slow -to-fast:
Store data in the file(say xml) -> load from disk(v.slow)->build DOM -> search
store data in DB -> search over indexes if not in RAM already(faster)
Store data(key-value pair) in memory(RAM) -> search  => (typical memcache) => facebook uses this for feed lookup => in-memory cache -> memcached 

* MySql DB engines:
- Archive: DB engine would keep data stored as compressed, makes it slower to query though.
- NDB(Network Storage Engine): database engine uses network based master-slave cluster for data storage to avoid spof. => adds to read heavy system as slaves can be used for reads => master-master would still be better=>requires consistency resolution.

*Active- active load balancer synonyms master-master system.
High-Availability - more than one instances of components(server, LB, DBs) in topology exchanging their heartbeat so if some dies other takes care of it's responsibility. => Active - Active / Active - Passive LB
Although like LBs, DBs won't have access to Http messages so we can't partition here based on text range or so.


* Multiple LB can also fail, need to plug them to diff switches.
*Geography based load balancing is still DNS level as it needs to be sticky => No round robin in here => Then how do we deal with down time? => wait for TTL to expire - check

*Traffic from Internet can be dropped off, added security like SSL once past LB into private server networks. All SSL certifications & cryptography are handles at LB now.
* Switches can act as firewalls - provide least previledges.
